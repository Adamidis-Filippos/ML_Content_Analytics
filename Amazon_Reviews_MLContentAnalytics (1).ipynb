{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQN7LbKFJagV",
        "outputId": "b53ef03b-30c5-4fcf-dae4-336f7dbd747c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "\n",
        "# Create a directory to store the datasets\n",
        "os.makedirs('datasets', exist_ok=True)\n",
        "\n",
        "# Define the URLs for the datasets\n",
        "train_url = \"https://www.dropbox.com/scl/fi/ghja3vpc34k78cg89uwjq/test.ft.txt?rlkey=e6rd56dtbv2ypms57m1l76brm&st=plgg4bhb&dl=0\"\n",
        "test_url = \"https://www.dropbox.com/scl/fi/iof2u1j31x5ffoytg2du5/train.ft.txt?rlkey=4xld1u112j0gogam297xajqg2&st=yjvlyblz&dl=0\"\n",
        "\n",
        "# Use wget to download the files\n",
        "!wget -O datasets/train.ft.txt {train_url}\n",
        "!wget -O datasets/test.ft.txt {test_url}\n",
        "\n",
        "# Verify the files are downloaded\n",
        "!ls datasets\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wH-sJH4oWBQT",
        "outputId": "51e205cf-3754-4bc3-e7f7-1ba147a1242d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-06 05:48:08--  https://www.dropbox.com/scl/fi/ghja3vpc34k78cg89uwjq/test.ft.txt?rlkey=e6rd56dtbv2ypms57m1l76brm\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6016:18::a27d:112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc87e1440f3a1de39400f07833cc.dl.dropboxusercontent.com/cd/0/inline/CYGpyOd88SJ2mQni8ZRuh767JQ6EahZBpYvRXBf1noKEzYAyyLBH5EF--cnTqSYXUizduCu0Q21jGqRlNdZat7cakgT9ag6zrKtt0eg1kN_eJ2d5CZKca5nynS1l79JJ-u8tbwHNWWS5X8yjeo3QlXca/file# [following]\n",
            "--2024-08-06 05:48:09--  https://uc87e1440f3a1de39400f07833cc.dl.dropboxusercontent.com/cd/0/inline/CYGpyOd88SJ2mQni8ZRuh767JQ6EahZBpYvRXBf1noKEzYAyyLBH5EF--cnTqSYXUizduCu0Q21jGqRlNdZat7cakgT9ag6zrKtt0eg1kN_eJ2d5CZKca5nynS1l79JJ-u8tbwHNWWS5X8yjeo3QlXca/file\n",
            "Resolving uc87e1440f3a1de39400f07833cc.dl.dropboxusercontent.com (uc87e1440f3a1de39400f07833cc.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\n",
            "Connecting to uc87e1440f3a1de39400f07833cc.dl.dropboxusercontent.com (uc87e1440f3a1de39400f07833cc.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 177376193 (169M) [text/plain]\n",
            "Saving to: ‘datasets/train.ft.txt’\n",
            "\n",
            "datasets/train.ft.t 100%[===================>] 169.16M  52.7MB/s    in 3.7s    \n",
            "\n",
            "2024-08-06 05:48:13 (46.3 MB/s) - ‘datasets/train.ft.txt’ saved [177376193/177376193]\n",
            "\n",
            "--2024-08-06 05:48:14--  https://www.dropbox.com/scl/fi/iof2u1j31x5ffoytg2du5/train.ft.txt?rlkey=4xld1u112j0gogam297xajqg2\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6016:18::a27d:112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc80fd5ad832cc54cb509033a89d.dl.dropboxusercontent.com/cd/0/inline/CYECeh5t3Z0-rP7_kVzyzYZABWThwam7dLy7doCneZGMr1b_BvfJKcFreIASH99q6-92Gfm35mYAziBd7H9wSG-81ciY46SEreEXw-0e60oFwI1DjbhmFDC41BQNfeUDFy1hjXPut17UTUZJYhi1-ZLa/file# [following]\n",
            "--2024-08-06 05:48:15--  https://uc80fd5ad832cc54cb509033a89d.dl.dropboxusercontent.com/cd/0/inline/CYECeh5t3Z0-rP7_kVzyzYZABWThwam7dLy7doCneZGMr1b_BvfJKcFreIASH99q6-92Gfm35mYAziBd7H9wSG-81ciY46SEreEXw-0e60oFwI1DjbhmFDC41BQNfeUDFy1hjXPut17UTUZJYhi1-ZLa/file\n",
            "Resolving uc80fd5ad832cc54cb509033a89d.dl.dropboxusercontent.com (uc80fd5ad832cc54cb509033a89d.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\n",
            "Connecting to uc80fd5ad832cc54cb509033a89d.dl.dropboxusercontent.com (uc80fd5ad832cc54cb509033a89d.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1597164432 (1.5G) [text/plain]\n",
            "Saving to: ‘datasets/test.ft.txt’\n",
            "\n",
            "datasets/test.ft.tx 100%[===================>]   1.49G  30.0MB/s    in 40s     \n",
            "\n",
            "2024-08-06 05:48:55 (38.3 MB/s) - ‘datasets/test.ft.txt’ saved [1597164432/1597164432]\n",
            "\n",
            "test.ft.txt  train.ft.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBWVktt5KaoI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification, get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IuFEf0ddKbAk"
      },
      "outputs": [],
      "source": [
        "# Reading data\n",
        "start_time = time.time()\n",
        "with open(\"datasets/train.ft.txt\", 'r', encoding='utf-8') as file:\n",
        "    train = file.readlines()\n",
        "\n",
        "with open(\"datasets/test.ft.txt\", 'r', encoding='utf-8') as file:\n",
        "    test = file.readlines()\n",
        "\n",
        "# Processing training data\n",
        "start_time = time.time()\n",
        "train_labels = []\n",
        "train_reviews = []\n",
        "\n",
        "for line in train:\n",
        "    if line.startswith(\"__label__\"):\n",
        "        label = int(line.split(' ')[0].replace('__label__', '').strip())\n",
        "        review = ' '.join(line.split(' ')[1:]).strip()\n",
        "        train_labels.append(label)\n",
        "        train_reviews.append(review)\n",
        "\n",
        "# Processing test data\n",
        "test_labels = []\n",
        "test_reviews = []\n",
        "\n",
        "for line in test:\n",
        "    if line.startswith(\"__label__\"):\n",
        "        label = int(line.split(' ')[0].replace('__label__', '').strip())\n",
        "        review = ' '.join(line.split(' ')[1:]).strip()\n",
        "        test_labels.append(label)\n",
        "        test_reviews.append(review)\n",
        "data_processing_time = time.time() - start_time\n",
        "\n",
        "# Creating DataFrames\n",
        "start_time = time.time()\n",
        "train_df = pd.DataFrame({\n",
        "    'review': train_reviews,\n",
        "    'label': train_labels\n",
        "})\n",
        "\n",
        "test_df = pd.DataFrame({\n",
        "    'review': test_reviews,\n",
        "    'label': test_labels\n",
        "})\n",
        "\n",
        "# Splitting data into training and validation sets\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
        "dataframe_creation_time = time.time() - start_time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DA8rUZpWKbOJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "355ff54d-e94f-4fa8-a1fc-b44aa1b60352"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, get_linear_schedule_with_warmup\n",
        "\n",
        "# Reading data\n",
        "start_time = time.time()\n",
        "with open(\"datasets/train.ft.txt\", 'r', encoding='utf-8') as file:\n",
        "    train = file.readlines()\n",
        "\n",
        "with open(\"datasets/test.ft.txt\", 'r', encoding='utf-8') as file:\n",
        "    test = file.readlines()\n",
        "data_reading_time = time.time() - start_time\n",
        "\n",
        "# Processing training data\n",
        "start_time = time.time()\n",
        "train_labels = []\n",
        "train_reviews = []\n",
        "\n",
        "for line in train:\n",
        "    if line.startswith(\"__label__\"):\n",
        "        label = int(line.split(' ')[0].replace('__label__', '').strip())\n",
        "        review = ' '.join(line.split(' ')[1:]).strip()\n",
        "        train_labels.append(label)\n",
        "        train_reviews.append(review)\n",
        "\n",
        "# Convert labels to 0 and 1\n",
        "train_labels = [label - 1 for label in train_labels]  # Convert 1 to 0 and 2 to 1\n",
        "\n",
        "# Processing test data\n",
        "test_labels = []\n",
        "test_reviews = []\n",
        "\n",
        "for line in test:\n",
        "    if line.startswith(\"__label__\"):\n",
        "        label = int(line.split(' ')[0].replace('__label__', '').strip())\n",
        "        review = ' '.join(line.split(' ')[1:]).strip()\n",
        "        test_labels.append(label)\n",
        "        test_reviews.append(review)\n",
        "\n",
        "# Convert labels to 0 and 1\n",
        "test_labels = [label - 1 for label in test_labels]  # Convert 1 to 0 and 2 to 1\n",
        "\n",
        "data_processing_time = time.time() - start_time\n",
        "\n",
        "# Creating DataFrames\n",
        "start_time = time.time()\n",
        "train_df = pd.DataFrame({\n",
        "    'review': train_reviews,\n",
        "    'label': train_labels\n",
        "})\n",
        "\n",
        "test_df = pd.DataFrame({\n",
        "    'review': test_reviews,\n",
        "    'label': test_labels\n",
        "})\n",
        "\n",
        "# Splitting data into training and validation sets\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
        "dataframe_creation_time = time.time() - start_time\n",
        "\n",
        "# Loading DistilBERT tokenizer\n",
        "start_time = time.time()\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "tokenizer_loading_time = time.time() - start_time\n",
        "\n",
        "class ReviewsDataset(Dataset):\n",
        "    def __init__(self, reviews, labels, tokenizer, max_len):\n",
        "        self.reviews = reviews\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.reviews)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        review = self.reviews[item]\n",
        "        label = self.labels[item]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            review,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=False,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'review_text': review,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Creating datasets\n",
        "start_time = time.time()\n",
        "train_dataset = ReviewsDataset(\n",
        "    reviews=train_df.review.to_numpy(),\n",
        "    labels=train_df.label.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=160\n",
        ")\n",
        "\n",
        "val_dataset = ReviewsDataset(\n",
        "    reviews=val_df.review.to_numpy(),\n",
        "    labels=val_df.label.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=160\n",
        ")\n",
        "\n",
        "test_dataset = ReviewsDataset(\n",
        "    reviews=test_df.review.to_numpy(),\n",
        "    labels=test_df.label.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=160\n",
        ")\n",
        "dataset_creation_time = time.time() - start_time\n",
        "\n",
        "# Increase batch size to lower memory consumption\n",
        "batch_size = 16\n",
        "\n",
        "# Creating data loaders\n",
        "start_time = time.time()\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "data_loader_creation_time = time.time() - start_time\n",
        "\n",
        "# Loading pre-trained DistilBERT model and unfreezing the last two layers\n",
        "start_time = time.time()\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
        "model_loading_time = time.time() - start_time\n",
        "\n",
        "# Unfreezing the last two layers\n",
        "for param in model.distilbert.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in model.distilbert.transformer.layer[-2:].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Set up optimizer and scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "total_steps = len(train_loader) * 3  # Assuming 3 epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "# Implement gradient accumulation\n",
        "accumulation_steps = 4\n",
        "\n",
        "# Training function\n",
        "def train_epoch(model, data_loader, optimizer, device, scheduler, accumulation_steps):\n",
        "    model = model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    for i, batch in enumerate(data_loader):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss = loss / accumulation_steps\n",
        "        loss.backward()\n",
        "\n",
        "        if (i + 1) % accumulation_steps == 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            scheduler.step()\n",
        "\n",
        "    return total_loss / len(data_loader)\n",
        "\n",
        "# Validation function\n",
        "def eval_model(model, data_loader, device):\n",
        "    model = model.eval()\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                labels=labels\n",
        "            )\n",
        "\n",
        "            loss = outputs.loss\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(data_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8UzLKDZKbe-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4c9a343-d5e8-4833-b0e5-93aa94c0ae87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Starting training...\n",
            "Epoch 1/3 completed in 2856.08 seconds.\n",
            "Train loss: 0.16679169678519248\n",
            "Val loss: 0.13235460030972027\n",
            "Epoch 2/3 completed in 2869.85 seconds.\n",
            "Train loss: 0.12774182451862143\n",
            "Val loss: 0.12698004063256085\n",
            "Epoch 3/3 completed in 2866.92 seconds.\n",
            "Train loss: 0.11188854023494059\n",
            "Val loss: 0.1196166014581453\n",
            "Saving the model...\n",
            "Model saved in 3.07 seconds.\n",
            "Evaluating the model...\n",
            "Validation predictions completed in 363.83 seconds.\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.96      0.96     39896\n",
            "           1       0.96      0.96      0.96     40104\n",
            "\n",
            "    accuracy                           0.96     80000\n",
            "   macro avg       0.96      0.96      0.96     80000\n",
            "weighted avg       0.96      0.96      0.96     80000\n",
            "\n",
            "Validation Accuracy: 0.9569375\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Training the model\n",
        "model = model.to(device)\n",
        "\n",
        "EPOCHS = 3\n",
        "\n",
        "# Timing the training process\n",
        "epoch_times = []\n",
        "print(\"Starting training...\")\n",
        "for epoch in range(EPOCHS):\n",
        "    epoch_start_time = time.time()\n",
        "    train_loss = train_epoch(model, train_loader, optimizer, device, scheduler, accumulation_steps)\n",
        "    val_loss = eval_model(model, val_loader, device)\n",
        "    epoch_end_time = time.time()\n",
        "    epoch_duration = epoch_end_time - epoch_start_time\n",
        "    epoch_times.append(epoch_duration)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{EPOCHS} completed in {epoch_duration:.2f} seconds.')\n",
        "    print(f'Train loss: {train_loss}')\n",
        "    print(f'Val loss: {val_loss}')\n",
        "\n",
        "# Save the model\n",
        "print(\"Saving the model...\")\n",
        "start_time = time.time()\n",
        "model.save_pretrained(\"saved_model_distilbert\")\n",
        "tokenizer.save_pretrained(\"saved_model_distilbert\")\n",
        "model_saving_time = time.time() - start_time\n",
        "print(f\"Model saved in {model_saving_time:.2f} seconds.\")\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Evaluating the model...\")\n",
        "def get_predictions(model, data_loader):\n",
        "    model = model.eval()\n",
        "    reviews = []\n",
        "    predictions = []\n",
        "    prediction_probs = []\n",
        "    real_values = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask\n",
        "            )\n",
        "            _, preds = torch.max(outputs.logits, dim=1)\n",
        "\n",
        "            reviews.extend(batch['review_text'])\n",
        "            predictions.extend(preds)\n",
        "            prediction_probs.extend(outputs.logits)\n",
        "            real_values.extend(labels)\n",
        "\n",
        "    predictions = torch.stack(predictions).cpu()\n",
        "    real_values = torch.stack(real_values).cpu()\n",
        "    return reviews, predictions, prediction_probs, real_values\n",
        "\n",
        "# Get predictions for validation set\n",
        "start_time = time.time()\n",
        "y_val_review_texts, y_val_pred, y_val_pred_probs, y_val_test = get_predictions(\n",
        "    model,\n",
        "    val_loader\n",
        ")\n",
        "val_predictions_time = time.time() - start_time\n",
        "print(f'Validation predictions completed in {val_predictions_time:.2f} seconds.')\n",
        "print('Validation Classification Report:')\n",
        "print(classification_report(y_val_test, y_val_pred))\n",
        "print('Validation Accuracy:', accuracy_score(y_val_test, y_val_pred))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Path to the saved model directory\n",
        "model_directory = \"/content/saved_model_distilbert\"\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(model_directory)\n",
        "print(\"Tokenizer loaded.\")\n",
        "\n",
        "# Load the model\n",
        "model = DistilBertForSequenceClassification.from_pretrained(model_directory)\n",
        "print(\"Model loaded.\")\n",
        "\n",
        "# Move the model to the appropriate device (CPU or GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Function to get predictions\n",
        "def get_predictions(model, data_loader):\n",
        "    model = model.eval()\n",
        "    reviews = []\n",
        "    predictions = []\n",
        "    prediction_probs = []\n",
        "    real_values = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask\n",
        "            )\n",
        "            _, preds = torch.max(outputs.logits, dim=1)\n",
        "\n",
        "            reviews.extend(batch['review_text'])\n",
        "            predictions.extend(preds)\n",
        "            prediction_probs.extend(outputs.logits)\n",
        "            real_values.extend(labels)\n",
        "\n",
        "    predictions = torch.stack(predictions).cpu()\n",
        "    real_values = torch.stack(real_values).cpu()\n",
        "    return reviews, predictions, prediction_probs, real_values\n",
        "\n",
        "# Get predictions for validation set\n",
        "start_time = time.time()\n",
        "y_val_review_texts, y_val_pred, y_val_pred_probs, y_val_test = get_predictions(\n",
        "    model,\n",
        "    val_loader\n",
        ")\n",
        "val_predictions_time = time.time() - start_time\n",
        "print(f'Validation predictions completed in {val_predictions_time:.2f} seconds.')\n",
        "print('Validation Classification Report:')\n",
        "print(classification_report(y_val_test, y_val_pred))\n",
        "print('Validation Accuracy:', accuracy_score(y_val_test, y_val_pred))\n",
        "\n",
        "# Randomly select 30% of the test dataset\n",
        "test_indices = np.random.choice(len(test_dataset), size=int(0.3 * len(test_dataset)), replace=False)\n",
        "test_subset = Subset(test_dataset, test_indices)\n",
        "test_loader_30 = DataLoader(test_subset, batch_size=128, shuffle=False)\n",
        "\n",
        "# Get predictions for the 30% test subset\n",
        "start_time = time.time()\n",
        "y_test_review_texts, y_test_pred, y_test_pred_probs, y_test_labels = get_predictions(\n",
        "    model,\n",
        "    test_loader_30\n",
        ")\n",
        "test_predictions_time = time.time() - start_time\n",
        "print(f'Test predictions completed in {test_predictions_time:.2f} seconds.')\n",
        "print('Test Classification Report:')\n",
        "print(classification_report(y_test_labels, y_test_pred))\n",
        "print('Test Accuracy:', accuracy_score(y_test_labels, y_test_pred))\n",
        "\n",
        "# Displaying results\n",
        "print(\"Results for the validation set:\")\n",
        "print(f\"Validation Accuracy: {accuracy_score(y_val_test, y_val_pred):.4f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_val_test, y_val_pred))\n",
        "\n",
        "print(\"\\nResults for the test set:\")\n",
        "print(f\"Test Accuracy: {accuracy_score(y_test_labels, y_test_pred):.4f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test_labels, y_test_pred))\n",
        "\n",
        "# Summary of times\n",
        "print(\"\\nSummary of Times:\")\n",
        "print(f\"Data reading time: {data_reading_time:.2f} seconds\")\n",
        "print(f\"Data processing time: {data_processing_time:.2f} seconds\")\n",
        "print(f\"Dataframe creation time: {dataframe_creation_time:.2f} seconds\")\n",
        "print(f\"Tokenizer loading time: {tokenizer_loading_time:.2f} seconds\")\n",
        "print(f\"Dataset creation time: {dataset_creation_time:.2f} seconds\")\n",
        "print(f\"Data loader creation time: {data_loader_creation_time:.2f} seconds\")\n",
        "print(f\"Model loading time: {model_loading_time:.2f} seconds\")\n",
        "print(f\"Model saving time: {model_saving_time:.2f} seconds\")\n",
        "print(f\"Validation predictions time: {val_predictions_time:.2f} seconds\")\n",
        "print(f\"Test predictions time: {test_predictions_time:.2f} seconds\")\n",
        "print(f\"Epoch times: {epoch_times}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7F0IIv6xzdf",
        "outputId": "966c65f4-e7f9-49ef-be26-75ce00a44d5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer loaded.\n",
            "Model loaded.\n",
            "Using device: cuda\n",
            "Validation predictions completed in 363.81 seconds.\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.96      0.96     39896\n",
            "           1       0.96      0.96      0.96     40104\n",
            "\n",
            "    accuracy                           0.96     80000\n",
            "   macro avg       0.96      0.96      0.96     80000\n",
            "weighted avg       0.96      0.96      0.96     80000\n",
            "\n",
            "Validation Accuracy: 0.9569375\n",
            "Test predictions completed in 4808.27 seconds.\n",
            "Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.96      0.96    539999\n",
            "           1       0.96      0.96      0.96    540001\n",
            "\n",
            "    accuracy                           0.96   1080000\n",
            "   macro avg       0.96      0.96      0.96   1080000\n",
            "weighted avg       0.96      0.96      0.96   1080000\n",
            "\n",
            "Test Accuracy: 0.9566342592592593\n",
            "Results for the validation set:\n",
            "Validation Accuracy: 0.9569\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.96      0.96     39896\n",
            "           1       0.96      0.96      0.96     40104\n",
            "\n",
            "    accuracy                           0.96     80000\n",
            "   macro avg       0.96      0.96      0.96     80000\n",
            "weighted avg       0.96      0.96      0.96     80000\n",
            "\n",
            "\n",
            "Results for the test set:\n",
            "Test Accuracy: 0.9566\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.96      0.96    539999\n",
            "           1       0.96      0.96      0.96    540001\n",
            "\n",
            "    accuracy                           0.96   1080000\n",
            "   macro avg       0.96      0.96      0.96   1080000\n",
            "weighted avg       0.96      0.96      0.96   1080000\n",
            "\n",
            "\n",
            "Summary of Times:\n",
            "Data reading time: 3.85 seconds\n",
            "Data processing time: 55.04 seconds\n",
            "Dataframe creation time: 3.21 seconds\n",
            "Tokenizer loading time: 3.52 seconds\n",
            "Dataset creation time: 0.00 seconds\n",
            "Data loader creation time: 0.00 seconds\n",
            "Model loading time: 2.37 seconds\n",
            "Model saving time: 3.07 seconds\n",
            "Validation predictions time: 363.81 seconds\n",
            "Test predictions time: 4808.27 seconds\n",
            "Epoch times: [2856.084079504013, 2869.8458676338196, 2866.9210596084595]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "CZA-CWua6Gk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZ3riGO6Kb5D",
        "outputId": "629cd8f0-3742-4772-dd6c-015be836c3ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'time' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9caa4c2d3ba7>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Confusion matrix for validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mval_cm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval_disp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_cm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_disp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBlues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
          ]
        }
      ],
      "source": [
        "# Confusion matrix for validation set\n",
        "start_time = time.time()\n",
        "val_cm = confusion_matrix(y_val_labels, y_val_pred)\n",
        "val_disp = ConfusionMatrixDisplay(confusion_matrix=val_cm)\n",
        "val_disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Validation Confusion Matrix\")\n",
        "plt.show()\n",
        "print(f\"Validation confusion matrix generated in {time.time() - start_time:.2f} seconds.\")\n",
        "\n",
        "# Confusion matrix for test set\n",
        "start_time = time.time()\n",
        "test_cm = confusion_matrix(y_test_labels, y_test_pred)\n",
        "test_disp = ConfusionMatrixDisplay(confusion_matrix=test_cm)\n",
        "test_disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Test Confusion Matrix\")\n",
        "plt.show()\n",
        "print(f\"Test confusion matrix generated in {time.time() - start_time:.2f} seconds.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33IqVKHVLdSv"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, precision_recall_curve, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to plot precision-recall curve\n",
        "def plot_precision_recall(y_true, y_pred_probs):\n",
        "    precision, recall, _ = precision_recall_curve(y_true, y_pred_probs[:, 1])\n",
        "    plt.figure()\n",
        "    plt.plot(recall, precision, marker='.')\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.title('Precision-Recall Curve')\n",
        "    plt.show()\n",
        "\n",
        "# Function to plot ROC curve\n",
        "def plot_roc_curve(y_true, y_pred_probs):\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_pred_probs[:, 1])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "# Print classification report for validation set\n",
        "print(\"Validation Classification Report:\")\n",
        "print(classification_report(y_val_labels, y_val_pred))\n",
        "\n",
        "# Print classification report for test set\n",
        "print(\"Test Classification Report:\")\n",
        "print(classification_report(y_test_labels, y_test_pred))\n",
        "\n",
        "# Plot precision-recall curve for test set\n",
        "plot_precision_recall(y_test_labels, y_test_pred_probs)\n",
        "\n",
        "# Plot ROC curve for test set\n",
        "plot_roc_curve(y_test_labels, y_test_pred_probs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLj-ohPWLdhG"
      },
      "outputs": [],
      "source": [
        "# Summary of times\n",
        "print(\"\\nSummary of Times:\")\n",
        "print(f\"Data reading time: {data_reading_time:.2f} seconds\")\n",
        "print(f\"Data processing time: {data_processing_time:.2f} seconds\")\n",
        "print(f\"Dataframe creation time: {dataframe_creation_time:.2f} seconds\")\n",
        "print(f\"Tokenizer loading time: {tokenizer_loading_time:.2f} seconds\")\n",
        "print(f\"Dataset creation time: {dataset_creation_time:.2f} seconds\")\n",
        "print(f\"Data loader creation time: {data_loader_creation_time:.2f} seconds\")\n",
        "print(f\"Model loading time: {model_loading_time:.2f} seconds\")\n",
        "print(f\"Model saving time: {model_saving_time:.2f} seconds\")\n",
        "print(f\"Validation predictions time: {val_predictions_time:.2f} seconds\")\n",
        "print(f\"Test predictions time: {test_predictions_time:.2f} seconds\")\n",
        "print(f\"Epoch times: {epoch_times}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QO1WERLAM6_A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ea85398-74d7-4ab3-a799-610238870d56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading GPT-2 tokenizer...\n",
            "Creating datasets for GPT-2...\n",
            "Creating data loaders for GPT-2...\n",
            "Loading pre-trained GPT-2 model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load GPT-2 tokenizer\n",
        "print(\"Loading GPT-2 tokenizer...\")\n",
        "start_time = time.time()\n",
        "gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token  # Set the pad token to eos token for GPT-2\n",
        "gpt2_tokenizer_loading_time = time.time() - start_time\n",
        "\n",
        "# Creating datasets for GPT-2\n",
        "print(\"Creating datasets for GPT-2...\")\n",
        "start_time = time.time()\n",
        "gpt2_train_dataset = ReviewsDataset(\n",
        "    reviews=train_df.review.to_numpy(),\n",
        "    labels=train_df.label.to_numpy(),\n",
        "    tokenizer=gpt2_tokenizer,\n",
        "    max_len=128  # Same max length as used for RoBERTa\n",
        ")\n",
        "\n",
        "gpt2_val_dataset = ReviewsDataset(\n",
        "    reviews=val_df.review.to_numpy(),\n",
        "    labels=val_df.label.to_numpy(),\n",
        "    tokenizer=gpt2_tokenizer,\n",
        "    max_len=128\n",
        ")\n",
        "\n",
        "gpt2_test_dataset = ReviewsDataset(\n",
        "    reviews=test_df.review.to_numpy(),\n",
        "    labels=test_df.label.to_numpy(),\n",
        "    tokenizer=gpt2_tokenizer,\n",
        "    max_len=128\n",
        ")\n",
        "gpt2_dataset_creation_time = time.time() - start_time\n",
        "\n",
        "# Creating data loaders for GPT-2\n",
        "print(\"Creating data loaders for GPT-2...\")\n",
        "start_time = time.time()\n",
        "gpt2_train_loader = DataLoader(gpt2_train_dataset, batch_size=batch_size, shuffle=True)\n",
        "gpt2_val_loader = DataLoader(gpt2_val_dataset, batch_size=batch_size)\n",
        "gpt2_test_loader = DataLoader(gpt2_test_dataset, batch_size=batch_size)\n",
        "gpt2_data_loader_creation_time = time.time() - start_time\n",
        "\n",
        "# Load pre-trained GPT-2 model\n",
        "print(\"Loading pre-trained GPT-2 model...\")\n",
        "start_time = time.time()\n",
        "gpt2_model = GPT2ForSequenceClassification.from_pretrained('gpt2', num_labels=2)\n",
        "gpt2_model.config.pad_token_id = gpt2_tokenizer.pad_token_id\n",
        "gpt2_model_loading_time = time.time() - start_time\n",
        "\n",
        "# Unfreezing the last two layers for GPT-2\n",
        "for param in gpt2_model.transformer.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in gpt2_model.transformer.h[-2:].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Set up optimizer and scheduler for GPT-2\n",
        "gpt2_optimizer = AdamW(gpt2_model.parameters(), lr=2e-5)\n",
        "gpt2_total_steps = len(gpt2_train_loader) * 3  # Assuming 3 epochs\n",
        "gpt2_scheduler = get_linear_schedule_with_warmup(\n",
        "    gpt2_optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=gpt2_total_steps\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijlFR5xXM7Ti",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "b2c088bd-27b9-4330-bf76-95704feea8d5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'device' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-8a748b9e1e15>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Training the GPT-2 model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgpt2_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpt2_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting GPT-2 training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgpt2_epoch_times\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Training the GPT-2 model\n",
        "gpt2_model = gpt2_model.to(device)\n",
        "\n",
        "print(\"Starting GPT-2 training...\")\n",
        "gpt2_epoch_times = []\n",
        "for epoch in range(EPOCHS):\n",
        "    epoch_start_time = time.time()\n",
        "    train_loss = train_epoch(gpt2_model, gpt2_train_loader, gpt2_optimizer, device, gpt2_scheduler, accumulation_steps)\n",
        "    val_loss = eval_model(gpt2_model, gpt2_val_loader, device)\n",
        "    epoch_end_time = time.time()\n",
        "    epoch_duration = epoch_end_time - epoch_start_time\n",
        "    gpt2_epoch_times.append(epoch_duration)\n",
        "\n",
        "    print(f'GPT-2 Epoch {epoch + 1}/{EPOCHS} completed in {epoch_duration:.2f} seconds.')\n",
        "    print(f'GPT-2 Train loss: {train_loss}')\n",
        "    print(f'GPT-2 Val loss: {val_loss}')\n",
        "\n",
        "# Save the GPT-2 model\n",
        "print(\"Saving the GPT-2 model...\")\n",
        "start_time = time.time()\n",
        "gpt2_model.save_pretrained(\"C:/Users/santo/Desktop/AUEB/ML Content Analytics/Amazon reviews/saved_model_gpt2\")\n",
        "gpt2_tokenizer.save_pretrained(\"C:/Users/santo/Desktop/AUEB/ML Content Analytics/Amazon reviews/saved_model_gpt2\")\n",
        "gpt2_model_saving_time = time.time() - start_time\n",
        "print(f\"GPT-2 Model saved in {gpt2_model_saving_time:.2f} seconds.\")\n",
        "\n",
        "# Evaluate the GPT-2 model\n",
        "print(\"Evaluating the GPT-2 model...\")\n",
        "start_time = time.time()\n",
        "y_val_review_texts, y_val_pred, y_val_pred_probs, y_val_test = get_predictions(\n",
        "    gpt2_model,\n",
        "    gpt2_val_loader\n",
        ")\n",
        "gpt2_val_predictions_time = time.time() - start_time\n",
        "print(f'GPT-2 Validation predictions completed in {gpt2_val_predictions_time:.2f} seconds.')\n",
        "print('GPT-2 Validation Classification Report:')\n",
        "print(classification_report(y_val_test, y_val_pred))\n",
        "print('GPT-2 Validation Accuracy:', accuracy_score(y_val_test, y_val_pred))\n",
        "\n",
        "# Get predictions for GPT-2 test set\n",
        "start_time = time.time()\n",
        "y_test_review_texts, y_test_pred, y_test_pred_probs, y_test_labels = get_predictions(\n",
        "    gpt2_model,\n",
        "    gpt2_test_loader\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxxwR9awORzH"
      },
      "outputs": [],
      "source": [
        "gpt2_test_predictions_time = time.time() - start_time\n",
        "print(f'GPT-2 Test predictions completed in {gpt2_test_predictions_time:.2f} seconds.')\n",
        "print('GPT-2 Test Classification Report:')\n",
        "print(classification_report(y_test_labels, y_test_pred))\n",
        "print('GPT-2 Test Accuracy:', accuracy_score(y_test_labels, y_test_pred))\n",
        "\n",
        "# Displaying results for GPT-2\n",
        "print(\"GPT-2 Results for the validation set:\")\n",
        "print(f\"GPT-2 Validation Accuracy: {accuracy_score(y_val_test, y_val_pred):.4f}\")\n",
        "print(\"GPT-2 Classification Report:\")\n",
        "print(classification_report(y_val_test, y_val_pred))\n",
        "\n",
        "print(\"\\nGPT-2 Results for the test set:\")\n",
        "print(f\"GPT-2 Test Accuracy: {accuracy_score(y_test_labels, y_test_pred):.4f}\")\n",
        "print(\"GPT-2 Classification Report:\")\n",
        "print(classification_report(y_test_labels, y_test_pred))\n",
        "\n",
        "# Summary of times for GPT-2\n",
        "print(\"\\nGPT-2 Summary of Times:\")\n",
        "print(f\"GPT-2 Tokenizer loading time: {gpt2_tokenizer_loading_time:.2f} seconds\")\n",
        "print(f\"GPT-2 Dataset creation time: {gpt2_dataset_creation_time:.2f} seconds\")\n",
        "print(f\"GPT-2 Data loader creation time: {gpt2_data_loader_creation_time:.2f} seconds\")\n",
        "print(f\"GPT-2 Model loading time: {gpt2_model_loading_time:.2f} seconds\")\n",
        "print(f\"GPT-2 Model saving time: {gpt2_model_saving_time:.2f} seconds\")\n",
        "print(f\"GPT-2 Validation predictions time: {gpt2_val_predictions_time:.2f} seconds\")\n",
        "print(f\"GPT-2 Test predictions time: {gpt2_test_predictions_time:.2f} seconds\")\n",
        "print(f\"GPT-2 Epoch times: {gpt2_epoch_times}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}